align="v",
labels=c("a","b"),
label_size = 30,
label_fontfamily = "Helvetica",
rel_heights = c(0.8,1),
rel_widths = c(0.5,0.8))
pa
pa <- plot_grid(p1,p2,
ncol=2,nrow=1,
axis="bt",
align="v",
labels=c("a","b"),
label_size = 30,
label_fontfamily = "Helvetica",
rel_heights = c(0.7,1),
rel_widths = c(0.5,0.8))
ggsave(filename=sprintf("Plots/%s.%s","Figure2a","eps"),
plot=pa,
width=fig_size[1],
height=fig_size[2]-3)
ggsave(filename=sprintf("Plots/%s.%s","Figure2a","eps"),
plot=pa,
width=fig_size[1]+2,
height=fig_size[2]-4)
p2 <- ggplot(bias, aes(x=Choice,y=p_gain,group=Condition)) +
stat_summary_bin(aes(y=p_gain, fill=Condition), fun="mean", geom="bar", binwidth=0.2, position=position_dodge(width=1)) +
geom_point(aes(color=Condition), position=position_jitterdodge(dodge.width=1, jitter.width=0.1),
fill="white", shape=21, stroke=point_stroke-0.3, size=point_size-2) +
#scale_color_manual(values="black") +
stat_summary(aes(color=Condition),fun.data=mean_se, fun.args = list(mult=n_sem), geom="errorbar", width=0.3, size=0.9, position=position_dodge(1)) + # "turquoise4"
geom_hline(yintercept=0.5, size=line_size, linetype="dashed") +
scale_y_continuous(expand=c(0,0), breaks=c(0,0.5,1), limits=c(0,1.02)) +
theme +
theme(axis.title.x=element_blank(),
#aspect.ratio=5/7,
plot.title = element_text(margin=margin(0,0,30,0))) +
labs(y="p(select S+)", title="Final Decisions Choices") +
scale_x_discrete(breaks = c("Chosen","Unchosen"), limits=c("Chosen","Unchosen"),
labels = c("Chosen" = expression(S[chosen]*" (learned)"),
"Unchosen" = expression(S[unchosen]*" (inferred)"))) +
scale_fill_brewer(palette=color_pallete) +
scale_color_brewer(palette=color_pallete)
pa <- plot_grid(p1,p2,
ncol=2,nrow=1,
axis="bt",
align="v",
labels=c("a","b"),
label_size = 30,
label_fontfamily = "Helvetica",
rel_heights = c(0.7,1),
rel_widths = c(0.5,0.8))
ggsave(filename=sprintf("Plots/%s.%s","Figure2a","eps"),
plot=pa,
width=fig_size[1]+2,
height=fig_size[2]-4)
p2 <- ggplot(bias, aes(x=Choice,y=p_gain,group=Condition)) +
stat_summary_bin(aes(y=p_gain, fill=Condition), fun="mean", geom="bar", binwidth=0.2, position=position_dodge(width=1)) +
geom_point(aes(color=Condition), position=position_jitterdodge(dodge.width=1, jitter.width=0.1),
fill="white", shape=21, stroke=point_stroke-0.3, size=point_size-2) +
#scale_color_manual(values="black") +
stat_summary(aes(color=Condition),fun.data=mean_se, fun.args = list(mult=n_sem), geom="errorbar", width=0.3, size=0.9, position=position_dodge(1)) + # "turquoise4"
geom_hline(yintercept=0.5, size=line_size, linetype="dashed") +
scale_y_continuous(expand=c(0,0), breaks=c(0,0.5,1), limits=c(0,1.02)) +
theme +
theme(axis.title.x=element_blank(),
aspect.ratio=7/5,
plot.title = element_text(margin=margin(0,0,30,0))) +
labs(y="p(select S+)", title="Final Decisions Choices") +
scale_x_discrete(breaks = c("Chosen","Unchosen"), limits=c("Chosen","Unchosen"),
labels = c("Chosen" = expression(S[chosen]*" (learned)"),
"Unchosen" = expression(S[unchosen]*" (inferred)"))) +
scale_fill_brewer(palette=color_pallete) +
scale_color_brewer(palette=color_pallete)
p2
pa <- plot_grid(p1,p2,
ncol=2,nrow=1,
axis="bt",
align="v",
labels=c("a","b"),
label_size = 30,
label_fontfamily = "Helvetica",
rel_heights = c(0.7,1),
rel_widths = c(0.5,0.8))
ggsave(filename=sprintf("Plots/%s.%s","Figure2a","eps"),
plot=pa,
width=fig_size[1]+2,
height=fig_size[2]-4)
ggsave(filename=sprintf("Plots/%s.%s","Figure2a","eps"),
plot=pa,
width=fig_size[1],
height=fig_size[2]-4)
p2 <- ggplot(bias, aes(x=Choice,y=p_gain,group=Condition)) +
stat_summary_bin(aes(y=p_gain, fill=Condition), fun="mean", geom="bar", binwidth=0.2, position=position_dodge(width=1)) +
geom_point(aes(color=Condition), position=position_jitterdodge(dodge.width=1, jitter.width=0.1),
fill="white", shape=21, stroke=point_stroke-0.3, size=point_size-2) +
#scale_color_manual(values="black") +
stat_summary(aes(color=Condition),fun.data=mean_se, fun.args = list(mult=n_sem), geom="errorbar", width=0.3, size=0.9, position=position_dodge(1)) + # "turquoise4"
geom_hline(yintercept=0.5, size=line_size, linetype="dashed") +
scale_y_continuous(expand=c(0,0), breaks=c(0,0.5,1), limits=c(0,1.02)) +
theme +
theme(axis.title.x=element_blank(),
aspect.ratio=13/12,
plot.title = element_text(margin=margin(0,0,30,0))) +
labs(y="p(select S+)", title="Final Decisions Choices") +
scale_x_discrete(breaks = c("Chosen","Unchosen"), limits=c("Chosen","Unchosen"),
labels = c("Chosen" = expression(S[chosen]*" (learned)"),
"Unchosen" = expression(S[unchosen]*" (inferred)"))) +
scale_fill_brewer(palette=color_pallete) +
scale_color_brewer(palette=color_pallete)
p2
pa <- plot_grid(p1,p2,
ncol=2,nrow=1,
axis="bt",
align="v",
labels=c("a","b"),
label_size = 30,
label_fontfamily = "Helvetica",
rel_heights = c(0.7,1),
rel_widths = c(0.5,0.8))
ggsave(filename=sprintf("Plots/%s.%s","Figure2a","eps"),
plot=pa,
width=fig_size[1],
height=fig_size[2]-4)
difference_scores_unchosen_Exp1 <- subset(difference_scores_unchosen, Exp=="Exp1")
difference_scores_unchosen_Exp1
n_fake_samples = 1000
min_x = min(difference_scores_unchosen_Exp1$pairs_acc_score)
max_x = max(difference_scores_unchosen_Exp1$pairs_acc_score)
min_x
max_x
model_draws = sum_coefs_difference_scores_unchosen_Exp1$M_draws_Exp1 %>%
mutate(intercept_memory = `(Intercept)`,
slope_memory = pairs_acc_score)
sum_coefs_difference_scores_unchosen_Exp1$M_draws_Exp1
predicted_draws_difference_scores_unchosen <- create_posterior_draws_lines(n_fake_samples, min_x, max_x, model_draws, conditions, conditions_col_names, is_logistic)
x_steps <- seq(min_x, max_x, length.out=n_fake_samples)
summary_draws <- c()
i
# find columns that correspond the current condition
intercept_col <- which(grepl(paste0("intercept_",conditions[i]),colnames(model_draws)))
slope_col <- which(grepl(paste0("slope_",conditions[i]),colnames(model_draws)))
intercept_col
intercept_col <- which(grepl(paste0("intercept_",conditions[i]),colnames(model_draws)))
intercept_col
colnames(model_draws)
grepl(paste0("intercept_",conditions[i])
paste0("intercept_",conditions[i])
paste0("intercept_",conditions[i])
conditions[i]
conditions = c("memory")
conditions_col_names = c()
is_logistic = 0
predicted_draws_difference_scores_unchosen <- create_posterior_draws_lines(n_fake_samples, min_x, max_x, model_draws, conditions, conditions_col_names, is_logistic)
# find columns that correspond the current condition
intercept_col <- which(grepl(paste0("intercept_",conditions[i]),colnames(model_draws)))
slope_col <- which(grepl(paste0("slope_",conditions[i]),colnames(model_draws)))
# predict the probability for a gain response for each posterior iteration in current x value
pred_fake <- as.data.frame(matrix(0,nrow=nrow(model_draws),ncol=n_fake_samples))
for (x in 1:n_fake_samples){
if (is_logistic==1){
pred_fake[,x] <- invlogit(as.numeric(unlist(model_draws[intercept_col] + model_draws[slope_col]*x_steps[x])))
} else {
pred_fake[,x] <- as.numeric(unlist(model_draws[intercept_col] + model_draws[slope_col]*x_steps[x]))
}
}
# create a table summarizing the draws for each x step
df_x <- data.frame(x = x_steps, obs = 1:length(x_steps))
df_pred <- pred_fake %>%
setNames(seq_len(ncol(.))) %>%
tibble::rownames_to_column("posterior_sample") %>%
tidyr::gather("obs", "fitted", setdiff(names(.), "posterior_sample")) %>%
group_by(obs) %>%
dplyr::summarise(median = median(fitted),
lower = quantile(fitted, 0.025),
upper = quantile(fitted, 0.975)) %>%
mutate(obs = as.numeric(obs)) %>%
left_join(df_x, by="obs") %>%
arrange(obs) %>%
mutate(condition = conditions[i])
summary_draws <- bind_rows(summary_draws, df_pred)
}
summary_draws
conditions_col_names
length(conditions_col_names)
# -----------------------
# General plotting themes
# -----------------------
theme <- theme_classic() +
theme(plot.title = element_text(hjust = 0.5, size = 28),
text = element_text(size=20,family="Helvetica"),
axis.title = element_text(size = 24),
axis.text = element_text(size = 21, color = "black"),
legend.position = "top",
legend.title = element_blank(),
legend.spacing.x = unit(0.2,'cm'),
axis.line = element_line(size = 1),
axis.ticks = element_blank(),
aspect.ratio = 2/3,
strip.background=element_blank(),
panel.grid.major = element_blank())
point_plot_theme <- theme_classic() +
theme(text = element_text(size=20,family="Helvetica"),
axis.title = element_text(size = 24),
axis.text = element_text(size = 21, color = "black"),
panel.spacing.x=unit(1,"line"),
axis.line=element_blank(), aspect.ratio=1) +
panel_border(colour="black", size=2, linetype=1, remove=FALSE)
# -----------------------------
# Plot Bayesian regression line
# -----------------------------
create_posterior_draws_lines <- function(n_fake_samples, min_x, max_x, model_draws, conditions, conditions_col_names, is_logistic){
library("arm")
library("dplyr")
# create x fake steps
x_steps <- seq(min_x, max_x, length.out=n_fake_samples)
summary_draws <- c()
for (i in 1:length(conditions)){
# find columns that correspond the current condition
intercept_col <- which(grepl(paste0("intercept_",conditions[i]),colnames(model_draws)))
slope_col <- which(grepl(paste0("slope_",conditions[i]),colnames(model_draws)))
# predict the probability for a gain response for each posterior iteration in current x value
pred_fake <- as.data.frame(matrix(0,nrow=nrow(model_draws),ncol=n_fake_samples))
for (x in 1:n_fake_samples){
if (is_logistic==1){
pred_fake[,x] <- invlogit(as.numeric(unlist(model_draws[intercept_col] + model_draws[slope_col]*x_steps[x])))
} else {
pred_fake[,x] <- as.numeric(unlist(model_draws[intercept_col] + model_draws[slope_col]*x_steps[x]))
}
}
# create a table summarizing the draws for each x step
df_x <- data.frame(x = x_steps, obs = 1:length(x_steps))
df_pred <- pred_fake %>%
setNames(seq_len(ncol(.))) %>%
tibble::rownames_to_column("posterior_sample") %>%
tidyr::gather("obs", "fitted", setdiff(names(.), "posterior_sample")) %>%
group_by(obs) %>%
dplyr::summarise(median = median(fitted),
lower = quantile(fitted, 0.025),
upper = quantile(fitted, 0.975)) %>%
mutate(obs = as.numeric(obs)) %>%
left_join(df_x, by="obs") %>%
arrange(obs) %>%
mutate(condition = conditions[i])
summary_draws <- bind_rows(summary_draws, df_pred)
}
if (length(conditions_col_names) > 0) {
summary_draws <- summary_draws %>% separate(condition, conditions_col_names)
}
return(summary_draws)
}
predicted_draws_difference_scores_unchosen <- create_posterior_draws_lines(n_fake_samples, min_x, max_x, model_draws, conditions, conditions_col_names, is_logistic)
predicted_draws_difference_scores_unchosen <- predicted_draws_difference_scores_unchosen %>%
mutate(unchosen_pgain_score = median,
pairs_acc_score = x)
difference_scores_unchosen_text <- sum_coefs_difference_scores_unchosen_Exp1$summary_coefs_Exp1 %>%
subset(Coefficient == "pairs_acc_score") %>%
mutate(text = sprintf("\u03b2(Memory) = \n%s", `Median and 95% HDI`)) %>%
mutate(x = -0.2,
y = -0.8) %>%
subset(Coefficient == "pairs_acc_score")
p4 <- ggplot(difference_scores_unchosen_Exp1, aes(y=unchosen_pgain_score,x=pairs_acc_score)) +
geom_point(size=point_size-1, fill="white", shape=21, stroke=point_stroke) +
theme +
point_plot_theme +
geom_ribbon(data = predicted_draws_difference_scores_unchosen,
aes(ymin=lower, ymax=upper), color="light grey") +
geom_line(data=predicted_draws_difference_scores_unchosen, aes(y=median), size=line_size*1.5) +
geom_hline(yintercept=0, size=line_size, linetype="dashed") +
geom_vline(xintercept=0, size=line_size,  linetype="dashed") +
scale_y_continuous(expand=c(0,0),  breaks=c(-1,0,1), limits=c(-1,1)) +
scale_x_continuous(expand=c(0,0), breaks=c(-0.5, 0, 0.5), limits=c(-0.55,0.55)) +
theme(legend.position="none", plot.title = element_text(margin=margin(0,0,30,0))) +
labs(y=expression(atop("p(select "*S[unchosen]*"+)","Baseline - Interference")),
x="Memory accuracy\nBaseline - Interference",
title="The effect of interference") +
geom_text(data=difference_scores_unchosen_text,  mapping=aes(x=x, y=y, label=text), size=8) +
scale_fill_brewer(palette=color_pallete) +
scale_color_brewer(palette=color_pallete)
p4
sum_coefs_difference_scores_unchosen_Exp1$summary_coefs_Exp1
memory_sdt <- dfs$memory %>%
group_by(Exp, PID, condition) %>%
dplyr::summarise(hits = sum(old_pair == 1 & pairs_acc == 1),
cr = sum(old_pair == 0 & pairs_acc == 1),
misses = sum(old_pair == 1 & pairs_acc == 0),
fa = sum(old_pair == 0 & pairs_acc == 0))
indices <- psycho::dprime(memory_sdt$hits, memory_sdt$fa, memory_sdt$misses, memory_sdt$cr)
memory_sdt <- cbind(memory_sdt, indices) %>%
gather(key = "type", value ="value", hits:c)
memory_sdt_sum <- memory_sdt %>%
group_by(Exp, type, condition) %>%
dplyr::summarise(mean = mean(value),
se = sd(value)/sqrt(n())) %>%
subset(type %in% c("dprime", "fa", "hits")) %>%
mutate(Condition = ifelse(condition==1, "Interference", "Baseline"))
memory_sdt_sum_group <- memory_sdt_sum %>%
group_by(Exp, type, Condition) %>%
mutate(`Mean and SE` = sprintf("%.2f \u00b1 %.2f", mean, se)) %>%
rename(Experiment = Exp, Type = type) %>%
dplyr::select(Experiment, Type, Condition, `Mean and SE`)
# print
memory_sdt_sum_group %>%
kbl(caption = "Signal Detection Theory Behavioral Results") %>%
kable_paper("hover", full_width = F, html_font = "Helvetica", position = "left")
dprime_df <- memory_sdt %>%
subset(type == "dprime") %>%
rename(dprime = value) %>%
mutate(condition_centered = ifelse(condition==1, 1, -1))
View(dprime_df)
difference_scores_unchosen <- dfs$final_decisions %>%
subset(!is.na(rt)) %>%
group_by(Exp, PID, condition) %>%
dplyr::summarise(unchosen_pgain = mean(higher_outcome_chosen[chosen_trial==0], na.rm=1)) %>%
spread(condition, unchosen_pgain) %>%
mutate(unchosen_pgain_score = `0` - `1`) %>%
dplyr::select(-c(`0`,`1`)) %>%
merge(dfs$memory %>% group_by(Exp, PID, condition) %>% dplyr::summarise(pairs_acc = mean(pairs_acc, na.rm=1)) %>% spread(condition, pairs_acc) %>% mutate(pairs_acc_score = `0` - `1`) %>% dplyr::select(-c(`0`,`1`)), by=c("Exp", "PID"))
difference_scores_unchosen_strategy <- difference_scores_unchosen %>%
mutate(strategy = ifelse(PID %in% inverse_strategy_PID, 1, 0))
M_difference_scores_unchosen_strategy_Exp1 <- stan_glm(
data = difference_scores_unchosen_strategy %>% subset(Exp=="Exp1" & strategy == 0),
unchosen_pgain_score ~ pairs_acc_score,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
difference_scores_unchosen_strategy <- difference_scores_unchosen %>%
mutate(strategy = ifelse(PID %in% inverse_strategy_PID, 1, 0))
# These are the people who explictly mentioned an inverse strategy
inverse_strategy_PID <- subset(dfs$debrief, Strategy==1)$PID
# inverse_strategy_PID <- c("0fnsb","cqMpS", "eoRdQ", "kYxEv", "l2ASo", "pjqfS", "2te35", "3sSYQ", "8pRjy", "9s8ph", "BxrGU", "DqtDo", "FZLzn", "HAvkp", "HSqqB", "HgayM", "JJKmU","JY6WO", "Jt02R", "QS6kW", "RLJAU", "V2T2h", "d3y2u", "eKQrN", "hXAw3", "ny1bP", "pcdhA" ,"x4Vzv", "y1DzQ")
difference_scores_unchosen_strategy <- difference_scores_unchosen %>%
mutate(strategy = ifelse(PID %in% inverse_strategy_PID, 1, 0))
M_difference_scores_unchosen_strategy_Exp1 <- stan_glm(
data = difference_scores_unchosen_strategy %>% subset(Exp=="Exp1" & strategy == 0),
unchosen_pgain_score ~ pairs_acc_score,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_difference_scores_unchosen_strategy_Exp1",
file = "../Data/Exp1/Models/Strategy/M_difference_scores_unchosen_strategy_Exp1.RData")
M_difference_scores_unchosen_strategy_Pilot <- stan_glm(
data = difference_scores_unchosen_strategy %>% subset(Exp=="Pilot" & strategy == 0),
unchosen_pgain_score ~ pairs_acc_score,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_difference_scores_unchosen_strategy_Pilot",
file = "../Data/Pilot/Models/Strategy/M_difference_scores_unchosen_strategy_Pilot.RData")
sum_coefs_difference_scores_unchosen_strategy_Exp1 <- create_summary_coefs(M_difference_scores_unchosen_strategy_Exp1, "Exp1")
sum_coefs_difference_scores_unchosen_strategy_Pilot <- create_summary_coefs(M_difference_scores_unchosen_strategy_Pilot, "Pilot")
# print table of coefs
bind_rows(sum_coefs_difference_scores_unchosen_strategy_Exp1$summary_coefs_Exp1,sum_coefs_difference_scores_unchosen_strategy_Pilot$summary_coefs_Pilot) %>%
kbl(caption = "Model coefficients - unchosen pairs difference scores") %>%
kable_paper("hover", full_width = F, html_font = "Helvetica", position = "left")
test <- difference_scores_unchosen_strategy %>% subset(Exp=="Pilot" & strategy == 0)
View(test)
difference_scores_unchosen_strategy %>% subset(Exp=="Exp1" & strategy == 0)
test <- difference_scores_unchosen_strategy %>% subset(Exp=="Exp1" & strategy == 0)
bind_rows(sum_coefs_difference_scores_unchosen_strategy_Exp1$summary_coefs_Exp1,sum_coefs_difference_scores_unchosen_strategy_Pilot$summary_coefs_Pilot) %>%
kbl(caption = "Model coefficients - unchosen pairs difference scores") %>%
kable_paper("hover", full_width = F, html_font = "Helvetica", position = "left")
save(list = "M_difference_scores_unchosen_strategy_Pilot",
file = "../Data/Pilot/Models/Strategy/M_difference_scores_unchosen_strategy_Pilot.RData")
library("psycho")
memory_sdt <- dfs$memory %>%
group_by(Exp, PID, condition) %>%
dplyr::summarise(hits = sum(old_pair == 1 & pairs_acc == 1),
cr = sum(old_pair == 0 & pairs_acc == 1),
misses = sum(old_pair == 1 & pairs_acc == 0),
fa = sum(old_pair == 0 & pairs_acc == 0))
indices <- psycho::dprime(memory_sdt$hits, memory_sdt$fa, memory_sdt$misses, memory_sdt$cr)
memory_sdt <- cbind(memory_sdt, indices) %>%
gather(key = "type", value ="value", hits:c)
memory_sdt_sum <- memory_sdt %>%
group_by(Exp, type, condition) %>%
dplyr::summarise(mean = mean(value),
se = sd(value)/sqrt(n())) %>%
subset(type %in% c("dprime", "fa", "hits")) %>%
mutate(Condition = ifelse(condition==1, "Interference", "Baseline"))
memory_sdt_sum_group <- memory_sdt_sum %>%
group_by(Exp, type, Condition) %>%
mutate(`Mean and SE` = sprintf("%.2f \u00b1 %.2f", mean, se)) %>%
rename(Experiment = Exp, Type = type) %>%
dplyr::select(Experiment, Type, Condition, `Mean and SE`)
dprime_df <- memory_sdt %>%
subset(type == "dprime") %>%
rename(dprime = value) %>%
mutate(condition_centered = ifelse(condition==1, 1, -1))
M_dprime_Exp1 <- stan_glm(data = subset(dprime_df, Exp=="Exp1"),
dprime ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_dprime_Exp1",
file = "../Data/Exp1/Models/M_dprime_Exp1.RData")
M_dprime_Pilot <- stan_glm(data = subset(dprime_df, Exp=="Pilot"),
dprime ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_dprime_Pilot",
file = "../Data/Pilot/Models/M_dprime_Pilot.RData")
fa_df <- memory_sdt %>%
subset(type == "fa") %>%
rename(fa = value) %>%
mutate(condition_centered = ifelse(condition==1, 1, -1))
# run model
M_fa_Exp1 <- stan_glm(data = subset(fa_df, Exp=="Exp1"),
fa ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_fa_Exp1",
file = "../Data/Exp1/Models/M_fa_Exp1.RData")
# pilot
M_fa_Pilot <- stan_glm(data = subset(fa_df, Exp=="Pilot"),
fa ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
hits_df <- memory_sdt %>%
subset(type == "hits") %>%
rename(hits = value) %>%
mutate(condition_centered = ifelse(condition==1, 1, -1))
# run model
M_hits_Exp1 <- stan_glm(data = subset(hits_df, Exp=="Exp1"),
hits ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_hits_Exp1",
file = "../Data/Exp1/Models/M_hits_Exp1.RData")
# pilot
M_hits_Pilot <- stan_glm(data = subset(hits_df, Exp=="Pilot"),
hits ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_hits_Pilot",
file = "../Data/Pilot/Models/M_hits_Pilot.RData")
fa_df <- memory_sdt %>%
subset(type == "fa") %>%
rename(fa = value) %>%
mutate(condition_centered = ifelse(condition==1, 1, -1))
# run model
M_fa_Exp1 <- stan_glm(data = subset(fa_df, Exp=="Exp1"),
fa ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_fa_Exp1",
file = "../Data/Exp1/Models/M_fa_Exp1.RData")
# pilot
M_fa_Pilot <- stan_glm(data = subset(fa_df, Exp=="Pilot"),
fa ~ condition_centered,
family = gaussian(),
adapt_delta = params$adapt_delta,
iter = params$iterations,
chains = params$chains,
warmup = params$warmup,
seed = 12345)
save(list = "M_fa_Pilot",
file = "../Data/Pilot/Models/M_fa_Pilot.RData")
sum_coefs_fa_Exp1 <- create_summary_coefs(M_fa_Exp1, "Exp1")
sum_coefs_fa_Pilot <- create_summary_coefs(M_fa_Pilot, "Pilot")
# print table of coefs
bind_rows(sum_coefs_fa_Exp1$summary_coefs_Exp1,sum_coefs_fa_Pilot$summary_coefs_Pilot) %>%
kbl(caption = "false alarms model coefficients") %>%
kable_paper("hover", full_width = F, html_font = "Helvetica", position = "left")
sum_coefs_hits_Exp1 <- create_summary_coefs(M_hits_Exp1, "Exp1")
sum_coefs_hits_Pilot <- create_summary_coefs(M_hits_Pilot, "Pilot")
# print table of coefs
bind_rows(sum_coefs_hits_Exp1$summary_coefs_Exp1,sum_coefs_hits_Pilot$summary_coefs_Pilot) %>%
kbl(caption = "hits model coefficients") %>%
kable_paper("hover", full_width = F, html_font = "Helvetica", position = "left")
sum_coefs_dprime_Exp1 <- create_summary_coefs(M_dprime_Exp1, "Exp1")
sum_coefs_dprime_Pilot <- create_summary_coefs(M_dprime_Pilot, "Pilot")
# print table of coefs
bind_rows(sum_coefs_dprime_Exp1$summary_coefs_Exp1,sum_coefs_dprime_Pilot$summary_coefs_Pilot) %>%
kbl(caption = "dprime model coefficients") %>%
kable_paper("hover", full_width = F, html_font = "Helvetica", position = "left")
warnings()
